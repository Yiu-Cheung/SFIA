# Generated by AI on 2024-12-19
# Reviewed by: AI Assistant
# Ticket: SFIA-005

# Layer: infrastructure
# Responsibility: Implement LLM generation using Google Gemini via Haystack
# Public API: GoogleGeminiGenerator.generate()

from typing import List, Dict, Any, Optional
from haystack.utils import Secret
from haystack_integrations.components.generators.google_ai import GoogleAIGeminiGenerator
from ...domain.models.document import Document
from ...domain.models.query import Query
from ...domain.models.response import Response
import os

class GoogleGeminiGenerator:
    """Google Gemini-based LLM generator implementation."""
    def __init__(
        self,
        model: str = "gemini-2.0-flash",
        api_key: Optional[str] = None,
        generation_config: Optional[Dict[str, Any]] = None
    ) -> None:
        """Initialize the Google Gemini generator."""
        if api_key is None:
            api_key = os.environ.get("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("Google Gemini API key must be provided via argument or GOOGLE_API_KEY env var.")
        self._generator = GoogleAIGeminiGenerator(
            model=model,
            api_key=Secret.from_token(api_key),
            generation_config=generation_config or {}
        )

    def generate(
        self,
        query: Query,
        documents: List[Document]
    ) -> Response:
        """Generate a response based on query and retrieved documents."""
        # Build context from documents
        context = "\n".join([doc.content for doc in documents])
        prompt = self._build_prompt(query.text, context)
        result = self._generator.run(parts=[prompt])
        replies = result.get("replies", [])
        if not replies:
            raise RuntimeError("No response generated from Google Gemini")
        return Response(
            content=replies[0],
            metadata={"model": "google_gemini", "replies_count": len(replies)}
        )

    def _build_prompt(self, query: str, context: str) -> str:
        """Build the prompt for the LLM."""
        return f"""You are a helpful assistant that answers questions based on the provided context.\nPlease answer the following question using ONLY the information provided in the context below.\nIf the exact answer is not found in the context, say \"I cannot find the specific information in the provided context.\"\n\nContext:\n{context}\n\nQuestion: {query}\n\nAnswer:""" 