# Generated by AI on 2024-12-19
# Reviewed by: AI Assistant
# Ticket: SFIA-001

# Layer: interface
# Responsibility: Handle CLI interactions and coordinate application services
# Public API: main()

import sys
import os
import argparse
from typing import Optional

from ..application.services.document_service import DocumentService
from ..application.services.qa_service import QAService
from ..infrastructure.persistence.haystack_document_store import HaystackDocumentStore

def main() -> None:
    parser = argparse.ArgumentParser(
        description="SFIA - Semantic File Information Assistant"
    )
    parser.add_argument(
        "query",
        help="The question to ask about the documents"
    )
    parser.add_argument(
        "--doc-folder",
        help="Path to folder containing documents"
    )
    parser.add_argument(
        "--model",
        default="llama3.2:latest",
        help="Ollama or Gemini model to use (default: llama3.2:latest or gemini-2.0-flash)"
    )
    parser.add_argument(
        "--url",
        default="http://localhost:11434",
        help="Ollama server URL (default: http://localhost:11434)"
    )
    parser.add_argument(
        "--llm-backend",
        choices=["ollama", "google"],
        default="ollama",
        help="LLM backend to use: 'ollama' or 'google' (default: ollama)"
    )
    parser.add_argument(
        "--google-api-key",
        default=None,
        help="Google Gemini API key (or set GOOGLE_API_KEY env var)"
    )
    parser.add_argument(
        "--use-haystack",
        action="store_true",
        default=True,
        help="Use Haystack XLSX converter (default: True)"
    )
    parser.add_argument(
        "--no-haystack",
        action="store_true",
        help="Disable Haystack converter and use legacy Excel processing"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug mode to show retrieved documents"
    )
    parser.add_argument(
        "--raw-excel-to-llm",
        action="store_true",
        help="Pass the raw Excel file to the LLM without converting to text first."
    )

    args = parser.parse_args()

    try:
        document_store = HaystackDocumentStore()
        # Select LLM backend with conditional import
        if args.llm_backend == "google":
            from ..infrastructure.ml.google_gemini_generator import GoogleGeminiGenerator
            llm_generator = GoogleGeminiGenerator(
                model=args.model if args.model else "gemini-2.0-flash",
                api_key=args.google_api_key or os.environ.get("GOOGLE_API_KEY")
            )
            print("Using Google Gemini as LLM backend.")
        else:
            from ..infrastructure.ml.ollama_generator import OllamaGenerator
            llm_generator = OllamaGenerator(
                model=args.model,
                url=args.url
            )
            print("Using Ollama as LLM backend.")
        use_haystack = args.use_haystack and not args.no_haystack
        # Initialize application services
        document_service = DocumentService(document_store)
        qa_service = QAService(document_store, llm_generator)
        if args.doc_folder and any(f.endswith((".xlsx", ".xls")) for f in os.listdir(args.doc_folder)):
            excel_files = [f for f in os.listdir(args.doc_folder) if f.endswith((".xlsx", ".xls"))]
            if excel_files:
                excel_file_path = os.path.join(args.doc_folder, excel_files[0])
                print(f"Processing Excel file: {excel_files[0]}")
                if args.raw_excel_to_llm:
                    print("Passing raw Excel file to LLM (no conversion).")
                else:
                    print(f"Using Haystack converter: {use_haystack}")
                print()
                response = qa_service.ask_question_excel_page_by_page(
                    args.query, excel_file_path, raw_excel_to_llm=args.raw_excel_to_llm
                )
                if args.debug:
                    print(f"\nDebug - Response metadata: {response.metadata}")
                print(f"\nAnswer: {response.content}")
                return
        if args.doc_folder:
            documents = document_service.load_from_folder(args.doc_folder)
            print(f"Loaded {len(documents)} documents")
            if args.debug:
                print("\nDebug - Retrieved documents:")
                for i, doc in enumerate(documents):
                    print(f"Document {i+1}: {doc.metadata.get('source', 'Unknown')}")
                    if 'sheet_name' in doc.metadata:
                        print(f"  Sheet: {doc.metadata['sheet_name']}")
                    print(f"  Content preview: {doc.content[:100]}...")
                    print()
        response = qa_service.ask_question(args.query)
        if args.debug:
            print(f"\nDebug - Response metadata: {response.metadata}")
        print(f"\nAnswer: {response.content}")
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 